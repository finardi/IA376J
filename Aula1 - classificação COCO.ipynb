{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1d4Ex4SmzzbOj6MkyxM3vkcj8mF3GUi2t",
      "authorship_tag": "ABX9TyOJMBk7pQ0ztgIxPozsywYL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/finardi/IA376J/blob/master/Aula1%20-%20classifica%C3%A7%C3%A3o%20COCO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGZSALWhqf9F",
        "colab_type": "text"
      },
      "source": [
        "# Aula 1\n",
        "> #### Paulo Ricardo Finardi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohmQlkVY36hG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c513b0f6-dc6c-423b-a76c-b21500534a1b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Sep 21 17:15:29 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl1QvYLfLZE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# basic\n",
        "import json\n",
        "import h5py\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter, OrderedDict\n",
        "\n",
        "# sklearn\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.utils.data import SequentialSampler, RandomSampler"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw_FZOyPlQRL",
        "colab_type": "text"
      },
      "source": [
        "# Preparação dos dados e criação do Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cffhEFnmxc5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/IA376J/Aula1/'\n",
        "train_path_labels = path+'TRAIN_CAPTIONS_coco_5_cap_per_img_5_min_word_freq.json'\n",
        "train_path_imgs = path+'TRAIN_IMAGES_coco_5_cap_per_img_5_min_word_freq.hdf5'\n",
        "\n",
        "val_path_labels = path+'VAL_CAPTIONS_coco_5_cap_per_img_5_min_word_freq.json'\n",
        "val_path_imgs = path+'VAL_IMAGES_coco_5_cap_per_img_5_min_word_freq.hdf5'\n",
        "\n",
        "test_path_labels = path+'TEST_CAPTIONS_coco_5_cap_per_img_5_min_word_freq.json'\n",
        "test_path_imgs = path+'TEST_IMAGES_coco_5_cap_per_img_5_min_word_freq.hdf5'\n",
        "\n",
        "word_map_path = path+'WORDMAP_coco_5_cap_per_img_5_min_word_freq.json'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRRa87IZzNuS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "17988b1c-016c-4012-9e5c-b6dac267173f"
      },
      "source": [
        "class Dataset_Aula1(Dataset):\n",
        "    def __init__(self, path_h5, path_labels, path_word_map):\n",
        "\n",
        "        self.images = h5py.File(path_h5, 'r')\n",
        "        self.labels = self._get_label(path_labels, path_word_map)\n",
        "        \n",
        "    def _get_label(self, path_label, path_wrd_map):\n",
        "\n",
        "        # Lê o arquivo json das labels (ints)\n",
        "        with open(path_label, \"rb\") as handle:\n",
        "            raw_labels = json.loads(handle.read())\n",
        "\n",
        "        # Lê o mapeamento dos rotulos das labels (str)\n",
        "        with open(path_wrd_map, \"rb\") as handle:\n",
        "            word_map = json.loads(handle.read())\n",
        "\n",
        "        # Lista que armazena as labels\n",
        "        labels = []\n",
        "        # Para cada sample in labels (cada img possui 5 labels, logo [::5])\n",
        "        for sample in raw_labels[::5]:\n",
        "            # Anexa a label somente se for um rótulo não 0, não start e não end\n",
        "            # subtrai 1 do i para os labels ficarem de 0 até 9 \n",
        "            labels.append([i-1 for i in sample if i != 0 \n",
        "                           and i != word_map['<start>'] \n",
        "                           and i != word_map['<end>']])\n",
        "                \n",
        "        # Se a quanditade de imagens é != do numero de labels\n",
        "        assert self.images['images'].shape[0] == len(raw_labels[::5])\n",
        "        return labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images['images'].shape[0]\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        assert idx >= 0, f'ERRO idx {idx}' \n",
        "        if idx >= self.__len__():\n",
        "            raise IndexError()\n",
        "\n",
        "        images = self.images['images'][idx] # shape=CHW\n",
        "        images = torch.from_numpy(images).type(torch.FloatTensor)\n",
        "        \n",
        "        # Labels é a forma de lista com 1 elemento\n",
        "        labels = self.labels[idx]\n",
        "        labels = torch.from_numpy(np.array(labels)).type(torch.LongTensor)\n",
        "\n",
        "        return images, labels.squeeze()\n",
        "\n",
        "#-------------------------------------------------------------------------\n",
        "\n",
        "def dev_dataloader(ds, number_of_samples=10, batch_size=32):\n",
        "    \"\"\" \n",
        "    Cria um pequeno dataloader com amostras do dataset de treino\n",
        "\n",
        "    Retorna:\n",
        "         dev_data_loader: dataLoader com k amostras do conj. de treino\n",
        "     -------------------\n",
        "     Argumentos:\n",
        "         ds - dataset de treino\n",
        "         number_of_samples - número de amostras\n",
        "         batch_size - tamanho do batch\n",
        "    \"\"\"\n",
        "    # K amostras serão utilizadas no dataloader    \n",
        "    k = number_of_samples\n",
        "\n",
        "    # Converte exemplos de imagem até k\n",
        "    img = [ds[i][0] for i in range(k)]\n",
        "    \n",
        "    # Converte exemplos de labels até k\n",
        "    label = [ds[i][1] for i in range(k)]\n",
        "    \n",
        "    # Se os tamanhos não são iguais é um erro\n",
        "    assert len(img) == len(label), f'ERRO lenghts imgs/labels'\n",
        "    \n",
        "    # Converte a lista de imagens para tensor\n",
        "    img = torch.tensor([t.numpy() for t in img])\n",
        "    \n",
        "    # Converte a lsita de labels para tensor\n",
        "    label = torch.tensor(label)\n",
        "    \n",
        "    # Cria um TensorDataset e Dataloader\n",
        "    dev_loader = DataLoader(\n",
        "        TensorDataset(img, label),\n",
        "        shuffle=True, \n",
        "        batch_size=batch_size)\n",
        "    return dev_loader\n",
        "\n",
        "#-------------------------------------------------------------------------\n",
        "\n",
        "def check_qtde_labels(ds):\n",
        "    \"\"\" \n",
        "    Confere o número de labels por classe\n",
        "\n",
        "    Retorna:\n",
        "         data: DataFrame com números de amostras por classe\n",
        "     -------------------\n",
        "     Argumentos:\n",
        "         ds - dataset de treino\n",
        "    \"\"\"\n",
        "\n",
        "    # Armazena os labels\n",
        "    labels_hist = []\n",
        "    # Para cada label no dataset de treino...\n",
        "    for _, label in ds:\n",
        "        # Anexa o label na lista\n",
        "        labels_hist.append(label)\n",
        "    \n",
        "    # Lê o json do word_map (rótulos das classes)\n",
        "    with open(word_map_path, \"rb\") as handle:\n",
        "                word_map = json.loads(handle.read())\n",
        "    \n",
        "    # Dict com k: qtde de exemplos -> v: classe\n",
        "    sample_class = dict({v:k for k,v in word_map.items()})\n",
        "    \n",
        "    # Dict com k: int da classe -> v: qtde de exemplos\n",
        "    number_samples = dict(Counter(np.array(labels_hist).flatten()))\n",
        "    \n",
        "    # Dataframe com valores dos Dicts k: sample_class -> v: number_samples\n",
        "    data = pd.DataFrame(list({v1:v2 for v1,v2 in \n",
        "                           zip(sample_class.values(),\n",
        "                               number_samples.values())}.items()))\n",
        "    \n",
        "    # Renomeia as colunas para melhor interpretabilidade\n",
        "    data = data.rename(columns={0:'Classe', 1:'Qtde-Exemplos'})\n",
        "\n",
        "    return data\n",
        "\n",
        "#-------------------------------------------------------------------------\n",
        "\n",
        "# Cria o dataset de treino\n",
        "ds = Dataset_Aula1(train_path_imgs, train_path_labels,  word_map_path)\n",
        "\n",
        "# Testando a função que cria um dev_dataloader\n",
        "dev_loader = dev_dataloader(ds, number_of_samples=100, batch_size=32)\n",
        "\n",
        "#-------------------------------------------------------------------------\n",
        "\n",
        "# Imprime o DataFramde da qtde de exemplos por classe\n",
        "check_qtde_labels(ds)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classe</th>\n",
              "      <th>Qtde-Exemplos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cat</td>\n",
              "      <td>3124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>truck</td>\n",
              "      <td>1518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>boat</td>\n",
              "      <td>1452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bird</td>\n",
              "      <td>1043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>house</td>\n",
              "      <td>1243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>car</td>\n",
              "      <td>2093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>airplane</td>\n",
              "      <td>2168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>horse</td>\n",
              "      <td>1890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>tree</td>\n",
              "      <td>2626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>dog</td>\n",
              "      <td>3660</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Classe  Qtde-Exemplos\n",
              "0       cat           3124\n",
              "1     truck           1518\n",
              "2      boat           1452\n",
              "3      bird           1043\n",
              "4     house           1243\n",
              "5       car           2093\n",
              "6  airplane           2168\n",
              "7     horse           1890\n",
              "8      tree           2626\n",
              "9       dog           3660"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGwa-6cIlTP_",
        "colab_type": "text"
      },
      "source": [
        "# Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isTW_ONJxc3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d82afa2-1124-4f59-c756-02953cae3b6c"
      },
      "source": [
        "BATCH_SZ = 128\n",
        "\n",
        "#-----------------------------------__DATASETS__-----------------------------------\n",
        "\n",
        "# Dataset de treino\n",
        "ds_train = Dataset_Aula1(train_path_imgs, train_path_labels,  word_map_path)\n",
        "\n",
        "# Dataset de validação\n",
        "ds_val = Dataset_Aula1(val_path_imgs, val_path_labels,  word_map_path)\n",
        "\n",
        "# Dataset de test\n",
        "ds_test = Dataset_Aula1(test_path_imgs, test_path_labels, word_map_path)\n",
        "\n",
        "#---------------------------------__DATALOADERS__----------------------------------\n",
        "\n",
        "# Dataloader é um dict com chaves train, val e test\n",
        "dataloaders = {\n",
        "        \n",
        "      'train': DataLoader(\n",
        "         ds_train,\n",
        "         batch_size=BATCH_SZ,\n",
        "         sampler = RandomSampler(ds_train), # seleciona batches randomicamente\n",
        "         num_workers=4,\n",
        "         pin_memory=True\n",
        "         ),\n",
        "               \n",
        "     'val': DataLoader(\n",
        "         ds_val,\n",
        "         batch_size=BATCH_SZ,\n",
        "         sampler = SequentialSampler(ds_val), # toma batches sequencialmente\n",
        "         num_workers=4,\n",
        "         pin_memory=True\n",
        "         ),\n",
        "\n",
        "    'test': DataLoader(\n",
        "         ds_test,\n",
        "         batch_size=BATCH_SZ,\n",
        "         sampler = SequentialSampler(ds_test), # toma batches sequencialmente\n",
        "         num_workers=4,\n",
        "         pin_memory=True\n",
        "         ),\n",
        "     }\n",
        "\n",
        "# Verificando os tamanhos dos dataloaders\n",
        "_ = {x: len(dataloaders[x]) for x in dataloaders.keys()}\n",
        "_"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': 8, 'train': 163, 'val': 8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmWAdLvVlWhQ",
        "colab_type": "text"
      },
      "source": [
        "# Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp6NQCGvlYe2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "571e6200-4052-477a-ea45-426102c297db"
      },
      "source": [
        "# Verifica qual é o device disponível \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Para os experimentos serem determinísticos\n",
        "manual_seed = 2357 # only primers ;)\n",
        "\n",
        "def deterministic(rep=True):\n",
        "    if rep:\n",
        "        np.random.seed(manual_seed)\n",
        "        torch.manual_seed(manual_seed)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed(manual_seed)\n",
        "            torch.cuda.manual_seed_all(manual_seed)\n",
        "        torch.backends.cudnn.enabled = False \n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        print(f'Experimento deterministico, seed: \\\n",
        "{manual_seed} -- ', end = '')\n",
        "        print(f'Existe {torch.cuda.device_count()} GPU \\\n",
        "{torch.cuda.get_device_name(0)} disponível.')\n",
        "    else:\n",
        "        print('Experimento randomico')\n",
        "\n",
        "deterministic()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experimento deterministico, seed: 2357 -- Existe 1 GPU Tesla T4 disponível.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MCA-cmV7nDM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6806d94f-9147-46d7-e7b3-0f80f983604d"
      },
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, channels, h, w, output):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ch = channels\n",
        "        self.h = h\n",
        "        self.w = w\n",
        "        self.out = output\n",
        "        \n",
        "        self.conv_layer = nn.Sequential(OrderedDict([\n",
        "            ('conv1', nn.Conv2d(3, self.ch, kernel_size=3, padding=1)),\n",
        "            ('bn1', nn.BatchNorm2d(self.ch)),\n",
        "            ('relu1', nn.ReLU()),\n",
        "            ('maxpool1', nn.MaxPool2d(3, stride=2)),\n",
        "            \n",
        "            ('conv2', nn.Conv2d(self.ch, 2 * self.ch, kernel_size=5, padding=1)),\n",
        "            ('bn2', nn.BatchNorm2d(2 * self.ch)),\n",
        "            ('relu2', nn.ReLU()),\n",
        "            ('maxpool2', nn.MaxPool2d(3, stride=2)),\n",
        "\n",
        "            ('conv3', nn.Conv2d(2 * self.ch, 3 * self.ch, kernel_size=3, padding=1)),\n",
        "            ('bn3', nn.BatchNorm2d(3 * self.ch)),\n",
        "            ('relu3', nn.ReLU()),\n",
        "            ('adaptative', nn.AdaptiveMaxPool2d((1, 1))),\n",
        "        ]))\n",
        "        \n",
        "        self.dense_layer =  nn.Linear(3 * self.ch, self.out)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        N,_,_,_ = x.shape\n",
        "        o = self.conv_layer(x)\n",
        "        o = o.view(N, -1) \n",
        "        return self.dense_layer(o)\n",
        "\n",
        "#---------------------------------------------------------------\n",
        "\n",
        "x,y = next(iter(dev_loader))  # utiliza x,y do dev_loader\n",
        "\n",
        "CH = 64 # numero de canais \n",
        "H = x[0].shape[1] # altura da imagem\n",
        "W = H # a imagem é quadrada, logo h=w\n",
        "OUT = 10 # numero de clases\n",
        "\n",
        "# Testando a rede com 1 exemplo\n",
        "model = SimpleCNN(CH, H, W, OUT)\n",
        "model(x).shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys2In7O_pOg0",
        "colab_type": "text"
      },
      "source": [
        "# Numero de Parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NYid9IQogG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "5c9d07eb-3062-43da-8d0e-fc6d539c8360"
      },
      "source": [
        "def count_parameters(model):\n",
        "    # Conta o numero de parametros se o parametro precisa de gradiente\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print('\\n','#' * 46,f'\\n # The model has {count_parameters(model):,}' \\\n",
        "       ' trainable parameters #\\n', '#' * 46,'\\n' )  \n",
        "model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ############################################## \n",
            " # The model has 430,794 trainable parameters #\n",
            " ############################################## \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleCNN(\n",
              "  (conv_layer): Sequential(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU()\n",
              "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu2): ReLU()\n",
              "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (conv3): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu3): ReLU()\n",
              "    (adaptative): AdaptiveMaxPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (dense_layer): Linear(in_features=192, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpJA4_Pm9Qi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, loss_fn, train_loader, optimizer, device):\n",
        "    # Coloca o modelo no modo de treinamento \n",
        "    model.train()\n",
        "\n",
        "    # Lista que guarda a loss total do batch\n",
        "    loss_train = []\n",
        "\n",
        "    # Para cada batch (imagem e label)...\n",
        "    for x, y in train_loader:\n",
        "\n",
        "        # Zera os gradientes\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Computa as predições (saída da rede)\n",
        "        y_pred = model(\n",
        "            x.to(device),\n",
        "            )\n",
        "        \n",
        "        # Calcula a loss\n",
        "        loss = loss_fn(y_pred, y.to(device))\n",
        "        \n",
        "        # Anexa a loss na lista\n",
        "        loss_train.append(loss.item())\n",
        "    \n",
        "        # Computa os gradientes\n",
        "        loss.backward()\n",
        "        \n",
        "        # Otimiza o modelo \n",
        "        optimizer.step()\n",
        "    \n",
        "    # Calcula a média da loss para o batch\n",
        "    ave_train_loss = sum(loss_train) / len(loss_train)\n",
        "    return ave_train_loss\n",
        "\n",
        "def test_model(model, loss_fn, valid_loader, device):\n",
        "    # Colaca o modelo em modo de avaliação (desliga os dropouts)\n",
        "    model.eval()\n",
        "    \n",
        "    # Listas para avaliação do modelo\n",
        "    preds, trues, loss_test = [],[],[]\n",
        "    \n",
        "    # Para cada batch (imagem e label)...\n",
        "    for x, y in valid_loader:\n",
        "        \n",
        "        # Não calcula nenhum gradiente\n",
        "        with torch.no_grad():\n",
        "            y_pred = model(\n",
        "            x.to(device),\n",
        "            )\n",
        "        \n",
        "        # Calcula a loss\n",
        "        loss = loss_fn(y_pred, y.to(device))\n",
        "        \n",
        "        # Anexa a loss na lista\n",
        "        loss_test.append(loss.item())\n",
        "\n",
        "        # Calcula as predições e envia os labels para cpu\n",
        "        preds += y_pred.argmax(-1).cpu().numpy().tolist()\n",
        "        trues += y.cpu().numpy().tolist()\n",
        "\n",
        "    # Calcula a média da loss para o batch\n",
        "    ave_test_loss = sum(loss_test) / len(loss_test)\n",
        "\n",
        "    # Calcula a acuracia    \n",
        "    preds = np.array(preds)\n",
        "    trues = np.array(trues)\n",
        "    acc = (1.* (preds==trues)).mean() \n",
        "    # Calcula o f1 com weighted (considera o desbalanceamento do dataset)\n",
        "    f1 = f1_score(trues, preds, average='weighted', zero_division=0)\n",
        "    \n",
        "    return ave_test_loss, acc, f1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK-hO_7mmis2",
        "colab_type": "text"
      },
      "source": [
        "# Overfit no batch dev_loader (100 amostras)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDdIIRS0mmNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9c9b3276-c869-4950-dd19-7030b226cef5"
      },
      "source": [
        "OverFit = True\n",
        "\n",
        "if OverFit:\n",
        "    model = SimpleCNN(CH, H, W, OUT).to(device)\n",
        "\n",
        "    # Num. de épocas\n",
        "    N_EPOCHS = 40\n",
        "\n",
        "    # Otimizador\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 2e-5)\n",
        "\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Para cada época...\n",
        "    for epoch_i in range(1, N_EPOCHS+1):\n",
        "\n",
        "        # Obtem a loss do dado de treino\n",
        "        loss_train = train_model(model, loss_fn, \n",
        "                                dev_loader, optimizer, device)\n",
        "        \n",
        "        # Obtem a loss, acc e f1 do dado de validação\n",
        "        loss_val, acc, f1 = test_model(model, loss_fn, \n",
        "                                    dev_loader, device)\n",
        "        if epoch_i==1:\n",
        "            print(f'Epoca [{epoch_i}/{N_EPOCHS}] |', end=' ')\n",
        "            print(f'Loss Treino: {loss_train:.3f}  ---- Loss Valid: \\\n",
        "{loss_val:.3f} -- Acc Valid: {acc:.3} -- F1 Valid: {f1:.3}')\n",
        "            \n",
        "        if epoch_i%10==0:\n",
        "            print(f'Epoca [{epoch_i}/{N_EPOCHS}] |', end=' ')\n",
        "            print(f'Loss Treino: {loss_train:.3f}  ---- Loss Valid: \\\n",
        "{loss_val:.3f} -- Acc Valid: {acc:.3} -- F1 Valid: {f1:.3}')\n",
        "\n",
        "    print(f'\\nFEITO!')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoca [1/40] | Loss Treino: 3.775  ---- Loss Valid: 2.407 -- Acc Valid: 0.12 -- F1 Valid: 0.0613\n",
            "Epoca [10/40] | Loss Treino: 1.660  ---- Loss Valid: 1.747 -- Acc Valid: 0.5 -- F1 Valid: 0.455\n",
            "Epoca [20/40] | Loss Treino: 1.233  ---- Loss Valid: 1.173 -- Acc Valid: 0.76 -- F1 Valid: 0.715\n",
            "Epoca [30/40] | Loss Treino: 1.009  ---- Loss Valid: 0.983 -- Acc Valid: 0.93 -- F1 Valid: 0.915\n",
            "Epoca [40/40] | Loss Treino: 0.848  ---- Loss Valid: 0.681 -- Acc Valid: 0.98 -- F1 Valid: 0.978\n",
            "\n",
            "FEITO!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIO4XRzQqVZD",
        "colab_type": "text"
      },
      "source": [
        "# Treino Completo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM1SPch_9P7v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4b667946-c3f1-4c8a-9b2b-fef0c0a72849"
      },
      "source": [
        "# Contagem de tempo\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "#----------------------------------------------------------------\n",
        "\n",
        "# Path para salvar as epocas do modelo\n",
        "path_save = '/content/drive/My Drive/Colab Notebooks/IA376J/Aula1/checkpoints/ch'\n",
        "\n",
        "\n",
        "# Se True carrega um modelo salvo\n",
        "CHECKPOINT = False\n",
        "if CHECKPOINT:\n",
        "    checkpoint = torch.load(path_save)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "\n",
        "else:\n",
        "    model = SimpleCNN(CH, H, W, OUT).to(device)\n",
        "\n",
        "# Para que os experimentos sejam deterministicos\n",
        "deterministic()\n",
        "\n",
        "# Num. de épocas\n",
        "N_EPOCHS = 2\n",
        "\n",
        "# Otimizador\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(), \n",
        "    lr=5e-3, \n",
        "    momentum=0.9,\n",
        "    weight_decay=5e-3\n",
        "    )\n",
        "\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "#----------------------------------------------------------------\n",
        "start.record()\n",
        "\n",
        "# Guarda as informações do treino\n",
        "training_stats = []\n",
        "\n",
        "# Para cada época...\n",
        "for epoch_i in range(1, N_EPOCHS+1):\n",
        "\n",
        "    # Obtem a loss do dado de treino\n",
        "    loss_train = train_model(model, loss, \n",
        "                             dataloaders['train'], optimizer, device)\n",
        "    \n",
        "    # Obtem a loss e acc do dado de validação\n",
        "    loss_val, acc, f1 = test_model(model, loss, \n",
        "                                        dataloaders['val'], device)\n",
        "    \n",
        "    print(f'Epoca [{epoch_i}/{N_EPOCHS}] |', end=' ')\n",
        "    print(f'Loss Treino: {loss_train:.3f}  ---- Loss Valid: \\\n",
        "{loss_val:.3f} -- Acc Valid: {acc:.3} -- F1 Valid: {f1:.3}')\n",
        "    \n",
        "    # Salva o estado do modelo na época atual\n",
        "    torch.save({\n",
        "            'epoch': epoch_i,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, path_save)\n",
        "\n",
        "    # Anexa as estatisticas da época de treinamento\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i,\n",
        "            'Training Loss': loss_train,\n",
        "            'Valid Loss': loss_val,\n",
        "            'Valid Acc': acc,\n",
        "            'Valid F1': f1,\n",
        "        }\n",
        "    )\n",
        "\n",
        "end.record()\n",
        "torch.cuda.synchronize()    \n",
        "#------------------------------------------------------------------\n",
        "print(f'\\nFEITO!')\n",
        "print(f'Tempo gasto: {start.elapsed_time(end)/1000/60 :.3f} min.')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experimento deterministico, seed: 2357 -- Existe 1 GPU Tesla T4 disponível.\n",
            "Epoca [1/2] | Loss Treino: 2.197  ---- Loss Valid: 2.499 -- Acc Valid: 0.146 -- F1 Valid: 0.0981\n",
            "Epoca [2/2] | Loss Treino: 1.863  ---- Loss Valid: 2.866 -- Acc Valid: 0.146 -- F1 Valid: 0.115\n",
            "\n",
            "FEITO!\n",
            "Tempo gasto: 11.681 min.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvQzkEW56u6n",
        "colab_type": "text"
      },
      "source": [
        "# Log do treino em DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hnlZBLU6yOW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "287075bb-1139-436b-8a16-3341a30e67e4"
      },
      "source": [
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "pd.set_option('precision', 3)\n",
        "df_stats"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid Loss</th>\n",
              "      <th>Valid Acc</th>\n",
              "      <th>Valid F1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.197</td>\n",
              "      <td>2.499</td>\n",
              "      <td>0.146</td>\n",
              "      <td>0.098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.863</td>\n",
              "      <td>2.866</td>\n",
              "      <td>0.146</td>\n",
              "      <td>0.115</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid Loss  Valid Acc  Valid F1\n",
              "epoch                                                \n",
              "1              2.197       2.499      0.146     0.098\n",
              "2              1.863       2.866      0.146     0.115"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGJf3gLc4dys",
        "colab_type": "text"
      },
      "source": [
        "# Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3wWcWoW28sW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b928e7e-bc2b-4394-c965-ccca9c87479d"
      },
      "source": [
        "loss_test, acc, f1 = test_model(model, loss, dataloaders['test'], device)\n",
        "print(f'Loss test {loss_test:.3f} -- Acc test: {acc:.3} -- F1 test: {f1:.3}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss test 2.922 -- Acc test: 0.128 -- F1 test: 0.0983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GWgq7KE54fm",
        "colab_type": "text"
      },
      "source": [
        "## Diversas estratégias podem ser utilizadas para melhorar essa solução, dois  pontos chaves são:\n",
        "1. #### Fazer aumento  e transformação dos dados de treinamento\n",
        "2. #### Usar os pesos de alguma rede pré-treinada como `backbone`, exemplo: Resnet\n",
        "\n",
        "# Fim\n"
      ]
    }
  ]
}